{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "from math import atan2, fabs, pi, pow, sqrt\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from pytz import timezone\n",
    "from requests import Session\n",
    "from shapely.geometry import Point\n",
    "\n",
    "with open('../.config/connections.json') as json_file:  \n",
    "    connections = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = connections['Lime']\n",
    "version = '0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "if 'extra' in c:\n",
    "    if 'headers' in c['extra']:\n",
    "        session.headers.update(c['extra']['headers'])\n",
    "if 'token_url' in c:\n",
    "    res = session.post(c['token_url'], data=c['auth_payload'])\n",
    "    session.headers.update({'Authorization': f'Bearer {res.json()[c[\"token_key\"]]}'})\n",
    "                            \n",
    "session.headers.update({\"Accept\": f\"application/vnd.mds.provider+json;version={version}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime(2019, 9, 1)\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "trip_params = {\n",
    "    'min_end_time': int(start_time.timestamp()) * 1000,\n",
    "    'max_end_time': int(end_time.timestamp()) * 1000\n",
    "}\n",
    "event_params = {\n",
    "    'start_time': int(start_time.timestamp()) * 1000,\n",
    "    'end_time': int(end_time.timestamp()) * 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_end_time': 1567292400000, 'max_end_time': 1567296000000}\n",
      "{'start_time': 1567292400000, 'end_time': 1567296000000}\n"
     ]
    }
   ],
   "source": [
    "print(trip_params)\n",
    "print(event_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _request(url, payload_key, params=None, results=[]):\n",
    "        \"\"\"\n",
    "        Internal helper for sending requests.\n",
    "\n",
    "        Returns payload(s).\n",
    "        \"\"\"\n",
    "        retries = 0\n",
    "        res = None\n",
    "\n",
    "        while res is None:\n",
    "            try:\n",
    "                res = session.get(url, params=params)\n",
    "                res.raise_for_status()\n",
    "            except Exception as err:\n",
    "                res = None\n",
    "                retries = retries + 1\n",
    "                if retries > 3:\n",
    "                    raise Exception(\n",
    "                        f\"Unable to retrieve response from {url} after {3}.  Aborting...\")\n",
    "\n",
    "                print(\n",
    "                    f\"{err}. Retrying in 10 seconds... (retry {retries}/3)\")\n",
    "                time.sleep(10)\n",
    "\n",
    "        if \"Content-Type\" in res.headers:\n",
    "            cts = res.headers[\"Content-Type\"].split(\";\")\n",
    "            if \"application/vnd.mds.provider+json\" not in cts:\n",
    "                print(\n",
    "                    f\"Incorrect content-type returned: {res.headers['Content-Type']}\")\n",
    "            cts = cts[1:]\n",
    "            for ct in cts:\n",
    "                if ct.strip().startswith(\"charset\"):\n",
    "                    pass\n",
    "                if not ct.strip().startswith(f\"version=0.3\"):\n",
    "                    print(\n",
    "                        f\"Incorrect content-type returned: {res.headers['Content-Type']}\")\n",
    "        else:\n",
    "            print(f\"Missing {self.version} content-type header.\")\n",
    "\n",
    "        page = res.json()\n",
    "\n",
    "        if page[\"data\"] is not None:\n",
    "            results.extend(page[\"data\"][payload_key])\n",
    "\n",
    "        if \"links\" in page:\n",
    "            next_page = page[\"links\"].get(\"next\")\n",
    "            if next_page is not None:\n",
    "                results = _request(url=next_page, payload_key=payload_key,\n",
    "                                        results=results)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = _request(c['api_url'].replace(':endpoint', 'trips').strip(), 'trips', params=trip_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(trips)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _request(session, url, data=None):\n",
    "    \"\"\"\n",
    "    Internal helper for sending requests.\n",
    "\n",
    "    Returns payload(s).\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    res = None\n",
    "\n",
    "    while res is None:\n",
    "        try:\n",
    "            res = session.post(url, data=data)\n",
    "            res.raise_for_status()\n",
    "        except Exception as err:\n",
    "            res = None\n",
    "            retries = retries + 1\n",
    "            if retries > 3:\n",
    "                print(\n",
    "                    f\"Unable to retrieve response from {url} after 3 tries.  Aborting...\")\n",
    "\n",
    "            print(\n",
    "                f\"Error while retrieving: {err}. Retrying in 10 seconds... (retry {retries}/3)\")\n",
    "            time.sleep(10)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.headers.update({\"Content-Type\": \"application/json\" })\n",
    "session.headers.update({\"Accept\": \"application/json\"})\n",
    "\n",
    "cores = cpu_count() #Number of CPU cores on your system\n",
    "executor = ThreadPoolExecutor(max_workers=cores*4)\n",
    "shst = df.route.map(lambda x: executor.submit(\n",
    "    _request, session, 'http://sharedstreets:3000/api/v1/match/point/bike', data=json.dumps(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shst.map(lambda x: 1 if x.done() else 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_result(x):\n",
    "    try:\n",
    "        return x.result().json()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shst'] = shst.map(safe_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the route to a DataFrame now to make mapping easier\n",
    "df['route'] = df.apply(\n",
    "    lambda x: gpd.GeoDataFrame.from_features(x.shst['features']) if x.shst is not None else gpd.GeoDataFrame.from_features(x.route['features']), axis=1)\n",
    "\n",
    "def parse_route(trip):\n",
    "    route = trip.route\n",
    "    route['trip_id'] = trip.trip_id\n",
    "    route['provider_id'] = trip.provider_id\n",
    "    route['vehicle_id'] = trip.vehicle_id\n",
    "    route['device_id'] = trip.device_id\n",
    "    route['vehicle_type'] = trip.vehicle_type\n",
    "    route['propulsion_type'] = trip.propulsion_type\n",
    "    return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_df = gpd.GeoDataFrame(\n",
    "    pd.concat(df.apply(parse_route, axis=1).values, sort=False).sort_values(\n",
    "        by=['trip_id', 'timestamp'], ascending=True\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "route_df.crs = {'init': 'epsg:4326'}\n",
    "route_df['datetime'] = route_df.timestamp.map(\n",
    "    lambda x: datetime.fromtimestamp(x / 1000).astimezone(timezone(\"US/Pacific\")))\n",
    "route_df['datetime'] = route_df.datetime.dt.round(\"L\")\n",
    "route_df['datetime'] = route_df.datetime.map(\n",
    "    lambda x: datetime.replace(x, tzinfo=None))\n",
    "route_df['date_key'] = route_df.datetime.map(\n",
    "    lambda x: int(x.strftime('%Y%m%d')))\n",
    "# Generate a hash to aid in merge operations\n",
    "route_df['hash'] = route_df.apply(lambda x: hashlib.md5((\n",
    "    x.trip_id + x.device_id + x.provider_id +\n",
    "    x.datetime.strftime('%d%m%Y%H%M%S%f')\n",
    ").encode('utf-8')).hexdigest(), axis=1)\n",
    "route_df['datetime'] = route_df.datetime.map(\n",
    "    lambda x: x.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "route_df = route_df.to_crs(epsg=3857)\n",
    "\n",
    "route_df['x'] = route_df.geometry.map(lambda g: g.x)\n",
    "route_df['y'] = route_df.geometry.map(lambda g: g.y)\n",
    "\n",
    "route_by_trip = route_df.groupby(['trip_id'])\n",
    "\n",
    "route_df['nt'] = route_by_trip.timestamp.shift(-1)\n",
    "route_df['nx'] = route_by_trip.x.shift(-1)\n",
    "route_df['ny'] = route_by_trip.y.shift(-1)\n",
    "\n",
    "# drop destination\n",
    "route_df = route_df.dropna()\n",
    "\n",
    "route_df['dx'] = route_df.apply(\n",
    "    lambda x: x.nx - x.x, axis=1)\n",
    "route_df['dy'] = route_df.apply(\n",
    "    lambda x: x.ny - x.y, axis=1)\n",
    "route_df['dt'] = route_df.apply(\n",
    "    lambda x: (x.nt - x.timestamp) / 1000, axis=1)\n",
    "\n",
    "def find_bearing(hit):\n",
    "    deg = atan2(hit.dx, hit.dy) / pi * 180\n",
    "    if deg < 0:\n",
    "        deg = deg + 360\n",
    "    return deg\n",
    "\n",
    "def find_speed(hit):\n",
    "    if hit['dt'] <= 0:\n",
    "        return 0\n",
    "\n",
    "    d = sqrt(pow((hit.dx), 2) + pow((hit.dy), 2))\n",
    "\n",
    "    return d / hit['dt']\n",
    "\n",
    "route_df['bearing'] = route_df.apply(find_bearing, axis=1)\n",
    "route_df['speed'] = route_df.apply(find_speed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "route_df['shstCandidates'] = route_df.shstCandidates.map(lambda x: pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_candidates(p):\n",
    "    df = p.shstCandidates.rename(index=str, columns={'bearing':'shstBearing'})\n",
    "    df['hash'] = p.hash\n",
    "    df['trip_id'] = p.trip_id\n",
    "    df['timestamp'] = p.timestamp\n",
    "    df['vehicle_type'] = p.vehicle_type\n",
    "    df['bearing'] = p.bearing\n",
    "    df['speed'] = p.speed\n",
    "    \n",
    "    return df\n",
    "\n",
    "shst_df = pd.concat(route_df.apply(expand_candidates, axis=1).values, sort=False).sort_values(\n",
    "    by=['trip_id', 'timestamp'], ascending=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeAngle(angle):\n",
    "    if angle < 0:\n",
    "        angle = angle + 360\n",
    "    return angle\n",
    "shst_df['bearing_diff'] = shst_df.apply(lambda x: fabs(normalizeAngle(x.bearing) - normalizeAngle(x.shstBearing)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['batch', 'date_key', 'seen', 'datetime', 'provider_id', 'propulsion_type'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-370c9cc58abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m'speed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m'seen'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;34m'batch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m ]]\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1269\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         )\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['batch', 'date_key', 'seen', 'datetime', 'provider_id', 'propulsion_type'] not in index\""
     ]
    }
   ],
   "source": [
    "shst_df.sort_values(\n",
    "    by=['hash', 'bearing_diff', 'score']\n",
    ").drop_duplicates(\n",
    "    subset=['hash']\n",
    ").drop_duplicates(\n",
    "    subset=['trip_id', 'geometryId'],\n",
    "    keep='last'\n",
    ").rename(\n",
    "    index=str,\n",
    "    columns={\n",
    "        'geometryId': 'shst_geometry_id',\n",
    "        'referenceId': 'shst_reference_id'\n",
    "    }\n",
    ")[[\n",
    "    'provider_id',\n",
    "    'date_key',\n",
    "    'shst_geometry_id',\n",
    "    'shst_reference_id',\n",
    "    'hash',\n",
    "    'datetime',\n",
    "    'vehicle_type',\n",
    "    'propulsion_type',\n",
    "    'bearing',\n",
    "    'speed',\n",
    "    'seen',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(route_df)[['geometry', 'hash']].to_file('../.data/shst_matches.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6541"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_df.shstCandidates.map(lambda x: 1 if x.empty else 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_df[route_df.shstCandidates.map(lambda x: x.empty)][['geometry', 'hash']].to_file('../.data/unmatched_shst.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
